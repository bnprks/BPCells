% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/singlecell_utils.R
\name{select_features_variance}
\alias{select_features_variance}
\alias{select_features_dispersion}
\alias{select_features_accessibility}
\alias{select_features_binned_dispersion}
\title{Feature selection functions}
\usage{
select_features_variance(mat, num_feats = 0.05, normalize = NULL, threads = 1L)

select_features_dispersion(
  mat,
  num_feats = 0.05,
  normalize = NULL,
  threads = 1L
)

select_features_accessibility(
  mat,
  num_feats = 0.05,
  normalize = NULL,
  threads = 1L
)

select_features_binned_dispersion(
  mat,
  num_feats = 0.05,
  n_bins = 20,
  threads = 1L
)
}
\arguments{
\item{mat}{(IterableMatrix) dimensions features x cells}

\item{num_feats}{(float) Number of features to mark as highly_variable. If 0 < num_feats < 1, then interpret it as a fraction of features.}

\item{normalize}{(function) Normalize the matrix prior to feature selection by calling normalize(mat) if it's not NULL.
For example, pass normalize_log() or normalize_tfidf().
If the normalize function accepts a threads argument, that will passed as normalize(mat, threads=threads).}

\item{threads}{(integer) Number of threads to use.}

\item{n_bins}{(integer) Number of bins to split features into in order to control for the relationship between mean expression and dispersion (see details).}
}
\value{
Return a dataframe with the following columns:
\itemize{
\item \code{feature}: Feature name.
\item \code{score}: Scoring of the feature, depending on the method used.
\item \code{highly_variable}: Logical vector of whether the feature is highly variable.
}

Each different feature selection method will have a different scoring method.
For each element \eqn{x_{ij}} in matrix \eqn{X} with \eqn{i} features and \eqn{j} cells, determine the score of
each feature \eqn{x_i} as follows:
\itemize{
\item \code{select_features_variance}: \eqn{\mathrm{Score}(x_i) = \frac{1}{n - 1} \sum_{j=1}^{n} \bigl(x_{ij} - \bar{x}_i\bigr)^2}
}

\itemize{
\item \code{select_features_dispersion}: \eqn{\mathrm{Score}(x_i) = \frac{\frac{1}{n - 1} \sum_{j=1}^{n} \bigl(x_{ij} - \bar{x}_i\bigr)^2}{\bar{x}_i}}
}

\itemize{
\item \code{select_features_accessibility}: \eqn{\mathrm{Score}(x_i) = \sum_{j=1}^{n} \bigl({x}_{ij}^{\mathrm{binarized}})\bigr)},  where \eqn{x_{ij}^{\mathrm{binarized}}} is defined as \eqn{1} if \eqn{x_{ij} != 0} and \eqn{0} otherwise.
}

\itemize{
\item \code{select_features_binned_dispersion}: Process described in \code{details}.
}
}
\description{
Apply a feature selection method to a non-normalized \verb{(features x cells)} matrix.  We recommend using counts matrices as input and
apply any normalizations prior to feature selection via the normalize argument (if available).  The output of these functions is a dataframe that has columns that
at the minimum include the feature names and a score for each feature.
}
\details{
\code{select_features_binned_dispersion} implements the approach from Satija et al. 2015:
\enumerate{
\item Bin features into equal-width bins by \code{log1p(mean)}
\item Calculate dispersion of each feature as \code{log(variance / mean)}
\item Z-score normalize dispersion within each bin, and select highest normalized dispersion across all bins
}

If the number of features within a bin is equal to 1, then dhe mean dispersion for that bin is set to 1.

This should be equivalent to \code{Seurat::FindVariableFeatures()} with \code{selection.method="mean.var.plot"}
and \code{scanpy.pp.highly_variable_genes()} with \code{flavor="seurat"}.
}
\examples{
set.seed(12345)
mat <- matrix(rpois(4*5, lambda=1), nrow=4, ncol=5)
rownames(mat) <- paste0("gene", seq_len(nrow(mat)))
mat

select_features_variance(
    mat, 
    num_feats=2, 
    normalize=normalize_log
)

# Because of how the BPCells normalize functions behave when the matrix 
# argument is missing, we can also customize the normalization parameters:
select_features_variance(
    mat,
    num_feats=2,
    normalize=normalize_log(scale_factor=20)
) 
}
\seealso{
\code{normalize_tfidf()} \code{normalize_log()}
}
